{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sparse_Attentive_Inpainting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ameyanjarlekar/Sparse-Attentive-Impainting/blob/master/Sparse_Attentive_Inpainting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr5SJKSVPpSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class AlexEnc_Dec(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexEnc_Dec, self).__init__()\n",
        "        self.RELU = nn.ReLU(inplace=True)\n",
        "        self.enc1a = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)\n",
        "        # nn.init.xavier_uniform_(self.enc1a.weight)\n",
        "        self.enc1 = nn.MaxPool2d(kernel_size=3, stride=2,return_indices=True)\n",
        "        self.enc2a = nn.Conv2d(64, 192, kernel_size=5, padding=2)\n",
        "        # nn.init.xavier_uniform_(self.enc2a.weight)\n",
        "        self.enc2 = nn.MaxPool2d(kernel_size=3, stride=2,return_indices=True)\n",
        "        self.enc3a = nn.Conv2d(192, 384, kernel_size=3, padding=1)\n",
        "        # nn.init.xavier_uniform_(self.enc3a.weight)\n",
        "        self.enc3b = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
        "        # nn.init.xavier_uniform_(self.enc3b.weight)\n",
        "        self.enc3c = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        # nn.init.xavier_uniform_(self.enc3b.weight)\n",
        "        self.enc3 =  nn.MaxPool2d(kernel_size=3, stride=2,return_indices=True)\n",
        "        \n",
        "        self.bridge = nn.Conv2d(256, 256,  kernel_size=3, padding=1)\n",
        "\n",
        "        # self.lin = nn.Linear(4096,4096)\n",
        "        #self.Encoder = nn.Sequential(\n",
        "        #    nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "        #    nn.ReLU(inplace=True),\n",
        "        #    nn.MaxPool2d(kernel_size=3, stride=2,return_indices=True),\n",
        "        #    nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "        #    nn.ReLU(inplace=True),\n",
        "        #    nn.MaxPool2d(kernel_size=3, stride=2,return_indices=True),\n",
        "        #    nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "        #    nn.ReLU(inplace=True),\n",
        "        #    nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "        #    nn.ReLU(inplace=True),\n",
        "        #    nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "        #    nn.ReLU(inplace=True),\n",
        "        #    nn.MaxPool2d(kernel_size=3, stride=2,return_indices=True),\n",
        "        #)\n",
        "\n",
        "        self.dec3 = nn.MaxUnpool2d(kernel_size=3, stride=2)\n",
        "        self.dec3c = nn.ConvTranspose2d(256, 256, kernel_size=3, padding=1)\n",
        "        # nn.init.xavier_uniform_(self.dec3c.weight)\n",
        "        self.dec3b = nn.ConvTranspose2d(256, 384, kernel_size=3, padding=1)\n",
        "        # nn.init.xavier_uniform_(self.dec3b.weight)\n",
        "        self.dec3a = nn.ConvTranspose2d(384, 192, kernel_size=3, padding=1)\n",
        "        # nn.init.xavier_uniform_(self.dec3a.weight)\n",
        "        self.dec2 = nn.MaxUnpool2d(kernel_size=3, stride=2)\n",
        "        self.dec2a = nn.ConvTranspose2d(192, 64, kernel_size=5, padding=2)\n",
        "        # nn.init.xavier_uniform_(self.dec2a.weight)\n",
        "        self.dec1 = nn.MaxUnpool2d(kernel_size=3, stride=2)\n",
        "        self.dec1a = nn.ConvTranspose2d(64, 3, kernel_size=11, stride=4, padding=2)\n",
        "        # nn.init.xavier_uniform_(self.dec1a.weight)\n",
        "\n",
        "        #self.Decoder = nn.Sequential(\n",
        "        #    nn.ConvTranspose2d(256, 256, kernel_size=3, padding=1),\n",
        "        #    nn.ReLU(inplace=True),\n",
        "        #    nn.MaxUnpool2d(kernel_size=3, stride=2),\n",
        "        #    nn.ConvTranspose2d(256, 384, kernel_size=3, padding=1),\n",
        "        #    nn.ReLU(inplace=True),\n",
        "        #    nn.ConvTranspose2d(384, 192, kernel_size=3, padding=1),\n",
        "        #    nn.ReLU(inplace=True),\n",
        "        #    nn.ConvTranspose2d(192, 64, kernel_size=5, padding=2),\n",
        "        #    nn.ReLU(inplace=True),\n",
        "        #    nn.MaxUnpool2d(kernel_size=3, stride=2),\n",
        "        #    nn.ConvTranspose2d(64, 3, kernel_size=11, stride=4, padding=2),\n",
        "        #    nn.ReLU(inplace=True),\n",
        "        #    nn.MaxUnpool2d(kernel_size=3, stride=2),\n",
        "        #)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = self.Encoder(x)\n",
        "        #x = self.Decoder(x)\n",
        "        #return x\n",
        "        # print(x.shape)\n",
        "        encconv1a = self.enc1a(x)             #conv1\n",
        "        encrel1a = self.RELU(encconv1a)       #relu\n",
        "        size1 = encrel1a.size()\n",
        "        #print(size1)\n",
        "        encpool1,idx1 = self.enc1(encrel1a)   #pool1\n",
        "        encconv2a = self.enc2a(encpool1)      #conv2\n",
        "        encrel2a = self.RELU(encconv2a)       #relu\n",
        "        size2 = encrel2a.size()\n",
        "        # print(size2)\n",
        "        encpool2,idx2 = self.enc2(encrel2a)   #pool2\n",
        "        encconv3a = self.enc3a(encpool2)      #conv3\n",
        "        encrel3a = self.RELU(encconv3a)       #relu \n",
        "        encconv3b = self.enc3b(encrel3a)      #conv4\n",
        "        encrel3b = self.RELU(encconv3b)       #relu\n",
        "        encconv3c = self.enc3c(encrel3b)      #conv5\n",
        "        encrel3c = self.RELU(encconv3c)       #relu\n",
        "        size3 = encrel3c.size()\n",
        "        # print(size3)\n",
        "        encpool3,idx3 = self.enc3(encrel3c)   #pool3\n",
        "        size4 = encpool3.size()\n",
        "        # print(size4)\n",
        "        bottleneck = self.bridge(encpool3)    #bridge conv\n",
        "        size5 = bottleneck.size()\n",
        "        # print(size5)\n",
        "        decpool3 = self.dec3(bottleneck, idx3, output_size = size3) #unpool3\n",
        "        size6 = decpool3.size()\n",
        "        # print(size6)\n",
        "        decconv3c = self.dec3c(decpool3)      #deconv5\n",
        "        decrel3c =self.RELU(decconv3c)        #relu\n",
        "        decconv3b = self.dec3b(decrel3c)      #deconv4\n",
        "        decrel3b = self.RELU(decconv3b)       #relu\n",
        "        decconv3a = self.dec3a(decrel3b)      #deconv3\n",
        "        decrel3a = self.RELU(decconv3a)       #relu\n",
        "        decpool2 = self.dec2(decrel3a, idx2, output_size = size2)  #unpool2\n",
        "        size7 = decpool2.size()\n",
        "        # print(size7)\n",
        "        decconv2a = self.dec2a(decpool2)      #deconv2\n",
        "        decrel2a = self.RELU(decconv2a)       #relu\n",
        "        decpool1 = self.dec1(decrel2a, idx1, output_size = size1)  #unpool1\n",
        "        size8 = decpool1.size()\n",
        "        # print(size8)\n",
        "        decconv1a = self.dec1a(decpool1)      #deconv1\n",
        "        sizef = decconv1a.size()\n",
        "        # print(sizef)\n",
        "        x = self.RELU(decconv1a)              #relu\n",
        "        return x\n",
        "\n",
        "AlexEnc_Dec = AlexEnc_Dec()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBhQWQR8eO_c",
        "colab_type": "code",
        "outputId": "ded12b44-8c88-429b-c81b-7c05831a859f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFRQWS95QeSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch, os\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as dset\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.utils import make_grid\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUyfViwDXSbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.0002\n",
        "max_epoch = 8\n",
        "batch_size = 64\n",
        "z_dim = 100\n",
        "image_size = 128\n",
        "g_conv_dim = 68\n",
        "d_conv_dim = 63\n",
        "log_step = 100\n",
        "sample_step = 500\n",
        "sample_num = 32\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBy9uV3EXy2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    #transforms.Scale(64),\n",
        "    transforms.Resize((215, 175)),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "dataset = ImageFolder(\"//content/datareqd\", transform)\n",
        "data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=16, drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm7OP42Wrsbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"/content/drive/My Drive/img_align_celeba.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75KyGYDVxwkA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls \"/content/img_align_celeba\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pgMxVMP2IQ4",
        "colab_type": "code",
        "outputId": "941e9a15-7ce9-47bb-a190-41477d00e2cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "import time\n",
        "criterion =  torch.nn.MSELoss(reduction='sum')\n",
        "start_time = time.time()\n",
        "optimizer = optim.Adam(AlexEnc_Dec.parameters(), lr=0.0001)\n",
        "for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
        "    for i, (data,val) in enumerate(data_loader):\n",
        "        #print(time.time()-start_time)\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        #inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        print(data.size())\n",
        "        #data = torch.tensor(data)\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = AlexEnc_Dec(data)\n",
        "        loss = criterion(outputs, data)\n",
        "        print(loss)\n",
        "        #if i%50 == 49:\n",
        "        #  print(\"loss:\",loss)\n",
        "        #  print(i)\n",
        "        #  print(epoch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(86371016., grad_fn=<MseLossBackward>)\n",
            "tensor(7964447.5000, grad_fn=<MseLossBackward>)\n",
            "tensor(2351750.7500, grad_fn=<MseLossBackward>)\n",
            "tensor(34164312., grad_fn=<MseLossBackward>)\n",
            "tensor(2833351.5000, grad_fn=<MseLossBackward>)\n",
            "tensor(1.4698e+08, grad_fn=<MseLossBackward>)\n",
            "tensor(6259965.5000, grad_fn=<MseLossBackward>)\n",
            "tensor(2116192.2500, grad_fn=<MseLossBackward>)\n",
            "tensor(2041345.8750, grad_fn=<MseLossBackward>)\n",
            "tensor(2006397.5000, grad_fn=<MseLossBackward>)\n",
            "tensor(2259437., grad_fn=<MseLossBackward>)\n",
            "tensor(1939852.1250, grad_fn=<MseLossBackward>)\n",
            "tensor(4907718.5000, grad_fn=<MseLossBackward>)\n",
            "tensor(3511765., grad_fn=<MseLossBackward>)\n",
            "tensor(2280611.5000, grad_fn=<MseLossBackward>)\n",
            "tensor(5432575.5000, grad_fn=<MseLossBackward>)\n",
            "tensor(3282654.5000, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQxZOyIhPlmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir datareqd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OcSfj2pT60H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}